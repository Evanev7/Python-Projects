{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import win32api\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import json as j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emoDi(prevAngle, json):\n",
    "    if len(json) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        emos = json[0][\"faceAttributes\"][\"emotion\"]\n",
    "        happy, sad = emos[\"happiness\"], emos[\"sadness\"]\n",
    "        newAngle = (prevAngle + (happy - sad)/30)\n",
    "        return newAngle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"example.json\") as file:\n",
    "    data = j.load(file)\n",
    "angle = 0\n",
    "x, y = win32api.GetCursorPos()\n",
    "while win32api.GetKeyState(1) == 1:\n",
    "    pass\n",
    "while win32api.GetKeyState(1) != 1:\n",
    "    pass\n",
    "while True:\n",
    "    angle = emoDi(angle, data)\n",
    "    dx,dy = (200*np.cos(angle),200*np.sin(angle))\n",
    "    win32api.SetCursorPos((int(x+dx),int(y+dy)))\n",
    "    sleep(0.005)\n",
    "    x,y = win32api.GetCursorPos()\n",
    "    x -= dx -(x+dx)%1\n",
    "    y -= dy -(y+dy)%1\n",
    "    if (win32api.GetAsyncKeyState(27)) != 0:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open (\"example.txt\") as file:\\n    data = j.load(file)\\nangle = 0\\nwhile True:\\n    angle = emoDi(angle, data)\\n    print(angle)\\n    #data = new pic'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math as m\n",
    "import json as j\n",
    "\n",
    "sensitivity = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"with open (\"example.txt\") as file:\n",
    "    data = j.load(file)\n",
    "angle = 0\n",
    "while True:\n",
    "    angle = emoDi(angle, data)\n",
    "    print(angle)\n",
    "    #data = new pic\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win32api.GetAsyncKeyState(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure.cognitiveservices.vision.face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fe7d77d456ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase64\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#from flask import Flask, render_template, request, jsonify\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mazure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcognitiveservices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFaceClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmsrest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthentication\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCognitiveServicesCredentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwin32api\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azure.cognitiveservices.vision.face'"
     ]
    }
   ],
   "source": [
    "import random, os, io, base64\n",
    "#from flask import Flask, render_template, request, jsonify\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import win32api\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import json as j\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "credentials = CognitiveServicesCredentials(\"c8c8240e711641f5b157b8eb37d6c908\")\n",
    "face_client = FaceClient(\"https://westeurope.api.cognitive.microsoft.com/\", credentials=credentials)\n",
    "\n",
    "emotions = ['anger','contempt','disgust','fear','happiness','sadness','surprise']\n",
    "\n",
    "\n",
    "def best_emotion(emotion):\n",
    "    emotions = {}\n",
    "    emotions['anger'] = emotion.anger\n",
    "    emotions['contempt'] = emotion.contempt\n",
    "    emotions['disgust'] = emotion.disgust\n",
    "    emotions['fear'] = emotion.fear\n",
    "    emotions['happiness'] = emotion.happiness\n",
    "    emotions['neutral'] = emotion.neutral\n",
    "    emotions['sadness'] = emotion.sadness\n",
    "    emotions['surprise'] = emotion.surprise\n",
    "    return max(zip(emotions.values(), emotions.keys()))[1]\n",
    "\n",
    "\n",
    "#app = Flask(__name__)\n",
    "'''\n",
    "@app.route('/')\n",
    "def home():\n",
    "\n",
    "\n",
    "    return render_template('HTMLfile.html')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def emoDi(prevAngle, json):\n",
    "    if len(json) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        emos = json[0][\"faceAttributes\"][\"emotion\"]\n",
    "        happy, sad = emos[\"happiness\"], emos[\"sadness\"]\n",
    "        newAngle = (prevAngle + (happy - sad)/30)\n",
    "        return newAngle\n",
    "\n",
    "angle = 0\n",
    "x, y = win32api.GetCursorPos()    \n",
    "\n",
    "'''\n",
    "@app.route('/square/', methods=['POST'])\n",
    "def square():\n",
    "\tnum = float(request.form.get('number', 0))\n",
    "\tsquare = num ** 2\n",
    "\tdata = {'square': square}\n",
    "\tdata = jsonify(data)\n",
    "\treturn data\n",
    "'''\n",
    "\n",
    "#@app.route('/loop',methods=['POST'])\n",
    "def loop():\n",
    "    while True:\n",
    "\t\n",
    "        retval, image = cap.read()\n",
    "        retval, buffer = cv2.imencode('.jpg', image)\n",
    "        image_bytes = base64.b64encode(buffer)\n",
    "        #body = request.get_json()\n",
    "\n",
    "        #image_bytes = base64.b64decode(body['image_base64'].split(',')[1])\n",
    "        image = io.BytesIO(image_bytes)\n",
    "\n",
    "        faces = face_client.face.detect_with_stream(image,\n",
    "                                                    return_face_attributes=['emotion'])\n",
    "\n",
    "        angle = emoDi(angle, faces)\n",
    "        #angle += 1/50\n",
    "        dx,dy = (200*np.cos(angle),200*np.sin(angle))\n",
    "        win32api.SetCursorPos((int(x+dx),int(y+dy)))\n",
    "        sleep(0.005)\n",
    "        x,y = win32api.GetCursorPos()\n",
    "        x -= dx -(x+dx)%1\n",
    "        y -= dy -(y+dy)%1\n",
    "        if (win32api.GetAsyncKeyState(27)) != 0:\n",
    "            break\n",
    "\n",
    "loop()\n",
    "'''\n",
    "@app.route('/result', methods=['POST'])\n",
    "def check_results():\n",
    "    body = request.get_json()\n",
    "    desired_emotion = body['emotion']\n",
    "\n",
    "    image_bytes = base64.b64decode(body['image_base64'].split(',')[1])\n",
    "    image = io.BytesIO(image_bytes)\n",
    "\n",
    "    faces = face_client.face.detect_with_stream(image,\n",
    "                                                return_face_attributes=['emotion'])\n",
    "\n",
    "    if len(faces) == 1:\n",
    "        detected_emotion = best_emotion(faces[0].face_attributes.emotion)\n",
    "\n",
    "        if detected_emotion == body['emotion']:\n",
    "            return jsonify({\n",
    "                'message': '✅ You won! You showed ' + desired_emotion\n",
    "            })\n",
    "        else:\n",
    "            return jsonify({\n",
    "                'message': '❌ You failed! You needed to show ' + \n",
    "                           desired_emotion + \n",
    "                           ' but you showed ' + \n",
    "                           detected_emotion\n",
    "            })\n",
    "    else:\n",
    "        return jsonify({\n",
    "            'message': '☠️ ERROR: No faces detected'\n",
    "        })\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
